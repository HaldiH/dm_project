{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to setup environment\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from processing_utils import *\n",
    "from rbf import RBF\n",
    "from rbf_optimization import objective\n",
    "import optuna\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import random\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "raw_dataset = pd.read_csv('./dataset/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Zero_point_energy_(kcal/mol@0K)  Enthalpy_(kcal/mol@298K)  \\\n",
      "36022                        34.348271                 38.496887   \n",
      "18528                       109.964328                120.907841   \n",
      "19324                        46.109933                 51.905503   \n",
      "16461                        74.605810                 82.719634   \n",
      "33006                       103.334974                111.401327   \n",
      "...                                ...                       ...   \n",
      "15124                        67.714824                 73.170953   \n",
      "35685                       140.466445                151.160630   \n",
      "28238                       109.600022                118.110369   \n",
      "24856                        56.954919                 61.485772   \n",
      "13105                       110.810632                120.093552   \n",
      "\n",
      "       Gibbs_energy_(kcal/mol@298K)  [  '  #     (  )  +  ...  P  S  \\  ]  c  \\\n",
      "36022                     15.726077  0  0  0  0  0  0  0  ...  0  0  0  0  0   \n",
      "18528                     83.423567  0  0  0  0  4  4  0  ...  0  0  0  0  6   \n",
      "19324                     26.812794  0  0  0  0  3  3  0  ...  0  0  0  0  6   \n",
      "16461                     50.773900  0  0  0  0  3  3  0  ...  0  1  0  0  6   \n",
      "33006                     81.292477  0  0  1  0  1  1  0  ...  0  0  0  0  6   \n",
      "...                             ... .. .. .. .. .. .. ..  ... .. .. .. .. ..   \n",
      "15124                     48.253299  0  0  0  0  1  1  0  ...  0  0  0  0  7   \n",
      "35685                    113.972045  1  0  1  0  3  3  0  ...  0  0  0  1  5   \n",
      "28238                     86.151021  1  0  0  0  2  2  0  ...  0  0  0  1  6   \n",
      "24856                     38.660578  0  0  0  0  0  0  0  ...  0  0  0  0  0   \n",
      "13105                     85.845443  0  0  0  0  4  4  0  ...  0  1  0  0  6   \n",
      "\n",
      "       l  n  o  r  s  \n",
      "36022  0  0  0  2  0  \n",
      "18528  2  0  0  0  0  \n",
      "19324  0  0  0  1  0  \n",
      "16461  0  0  0  0  0  \n",
      "33006  0  0  0  0  0  \n",
      "...   .. .. .. .. ..  \n",
      "15124  0  3  1  0  0  \n",
      "35685  0  1  0  0  0  \n",
      "28238  0  0  0  1  0  \n",
      "24856  0  0  0  1  0  \n",
      "13105  0  0  0  0  0  \n",
      "\n",
      "[6432 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = encode_smiles_column_of(\n",
    "    prune_dataset_lines(\n",
    "        raw_dataset,\n",
    "        remove_nan_lines=False,\n",
    "        remove_nan_cols=True,\n",
    "        remove_duplicates=True\n",
    "    ),\n",
    "    strategy='count_encoding'\n",
    ")\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_train_data(\n",
    "    dataset,\n",
    "    targets_columns=['Energy_(kcal/mol)', 'Energy DG:kcal/mol)'],\n",
    "    random_state=None,\n",
    "    as_numpy=False\n",
    ")\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying RBF with SMILES dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41380958903277704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf = RBF(n_clusters=8, sigma=3.14, normalize=True).fit(X_train, y_train)\n",
    "y_pred = rbf.predict(X_val)\n",
    "r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-22 03:15:25,335]\u001b[0m A new study created in memory with name: RBF hyperparameters optimization\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:31,206]\u001b[0m Trial 0 finished with value: 0.98135420424988 and parameters: {'n_clusters': 214, 'sigma': 6.67449361023077}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:36,502]\u001b[0m Trial 1 finished with value: 0.7012599466442445 and parameters: {'n_clusters': 232, 'sigma': 1.5569932963228452}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:39,921]\u001b[0m Trial 2 finished with value: 0.8376422934679795 and parameters: {'n_clusters': 121, 'sigma': 2.9478083286897463}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:42,676]\u001b[0m Trial 3 finished with value: 0.9757199444596591 and parameters: {'n_clusters': 86, 'sigma': 8.902273948388247}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:45,726]\u001b[0m Trial 4 finished with value: 0.9702703230067746 and parameters: {'n_clusters': 108, 'sigma': 7.356462871710014}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:48,899]\u001b[0m Trial 5 finished with value: 0.9612436858254948 and parameters: {'n_clusters': 128, 'sigma': 6.246328659356595}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:50,941]\u001b[0m Trial 6 finished with value: 0.8935768940937345 and parameters: {'n_clusters': 31, 'sigma': 7.9786737427691286}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:54,375]\u001b[0m Trial 7 finished with value: 0.9091699685082529 and parameters: {'n_clusters': 146, 'sigma': 3.8023306662076406}. Best is trial 0 with value: 0.98135420424988.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:15:58,762]\u001b[0m Trial 8 finished with value: 0.9841407381471855 and parameters: {'n_clusters': 203, 'sigma': 7.23570419319228}. Best is trial 8 with value: 0.9841407381471855.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:16:02,155]\u001b[0m Trial 9 finished with value: 0.9832801282493665 and parameters: {'n_clusters': 144, 'sigma': 8.77773721448056}. Best is trial 8 with value: 0.9841407381471855.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse = 3476501.6950129895\n",
      "Test R2 = 0.9845480178552618\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name=\"RBF hyperparameters optimization\"\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial, X_train, y_train, X_val, y_val, normalize=True, metric=r2_score),\n",
    "    n_trials=10,\n",
    "    # n_jobs=-1 # doesn't work well with my computer\n",
    ")\n",
    "\n",
    "rbf = RBF(\n",
    "    study.best_params[\"n_clusters\"],\n",
    "    study.best_params[\"sigma\"],\n",
    "    normalize=True\n",
    ").fit(X_train, y_train)\n",
    "y_pred = rbf.predict(X_test)\n",
    "print(\"Test mse =\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Test R2 =\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_clusters': 117, 'sigma': 9.91554131454891}\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances w.r.t. training dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESSAIS = 50\n",
    "mses = [[] for _ in range(N_ESSAIS)]\n",
    "r2_scores = [[] for _ in range(N_ESSAIS)]\n",
    "percentages = np.linspace(0.2, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-22 03:16:06,870]\u001b[0m A new study created in memory with name: RBF hyperparameters optimization for percentage p=0.2 Essai=0\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:16:11,049]\u001b[0m Trial 0 finished with value: 0.9875319358473407 and parameters: {'n_clusters': 145, 'sigma': 9.091027919331822}. Best is trial 0 with value: 0.9875319358473407.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:16:16,309]\u001b[0m Trial 1 finished with value: 0.988877802617131 and parameters: {'n_clusters': 117, 'sigma': 9.91554131454891}. Best is trial 1 with value: 0.988877802617131.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:16:23,235]\u001b[0m Trial 2 finished with value: 0.967788432271865 and parameters: {'n_clusters': 240, 'sigma': 4.577201865147072}. Best is trial 1 with value: 0.988877802617131.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:16:25,713]\u001b[0m Trial 3 finished with value: 0.7656549153563987 and parameters: {'n_clusters': 57, 'sigma': 2.7570780496657603}. Best is trial 1 with value: 0.988877802617131.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hugo/Projects/dm_project/rbf.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=12'>13</a>\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m get_train_data(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=13'>14</a>\u001b[0m     dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=14'>15</a>\u001b[0m     targets_columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mEnergy_(kcal/mol)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEnergy DG:kcal/mol)\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=15'>16</a>\u001b[0m     random_state\u001b[39m=\u001b[39mrandom_state,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=16'>17</a>\u001b[0m     as_numpy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=19'>20</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=20'>21</a>\u001b[0m     direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=21'>22</a>\u001b[0m     study_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRBF hyperparameters optimization for percentage p=\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m Essai=\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=22'>23</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=24'>25</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=25'>26</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: objective(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=26'>27</a>\u001b[0m         trial, X_train, y_train, X_val, y_val, normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, metric\u001b[39m=\u001b[39;49mr2_score),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=27'>28</a>\u001b[0m     n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=28'>29</a>\u001b[0m     \u001b[39m# n_jobs=-1\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=31'>32</a>\u001b[0m rbf \u001b[39m=\u001b[39m RBF(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=32'>33</a>\u001b[0m     study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mn_clusters\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=33'>34</a>\u001b[0m     study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=34'>35</a>\u001b[0m     normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=35'>36</a>\u001b[0m )\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=36'>37</a>\u001b[0m y_pred \u001b[39m=\u001b[39m rbf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m _optimize(\n\u001b[1;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    410\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/hugo/Projects/dm_project/rbf.ipynb Cell 11'\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=12'>13</a>\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m get_train_data(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=13'>14</a>\u001b[0m     dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=14'>15</a>\u001b[0m     targets_columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mEnergy_(kcal/mol)\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEnergy DG:kcal/mol)\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=15'>16</a>\u001b[0m     random_state\u001b[39m=\u001b[39mrandom_state,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=16'>17</a>\u001b[0m     as_numpy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=19'>20</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=20'>21</a>\u001b[0m     direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=21'>22</a>\u001b[0m     study_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRBF hyperparameters optimization for percentage p=\u001b[39m\u001b[39m{\u001b[39;00mp\u001b[39m}\u001b[39;00m\u001b[39m Essai=\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=24'>25</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=25'>26</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: objective(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=26'>27</a>\u001b[0m         trial, X_train, y_train, X_val, y_val, normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, metric\u001b[39m=\u001b[39;49mr2_score),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=27'>28</a>\u001b[0m     n_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=28'>29</a>\u001b[0m     \u001b[39m# n_jobs=-1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=31'>32</a>\u001b[0m rbf \u001b[39m=\u001b[39m RBF(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=32'>33</a>\u001b[0m     study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mn_clusters\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=33'>34</a>\u001b[0m     study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=34'>35</a>\u001b[0m     normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=35'>36</a>\u001b[0m )\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hugo/Projects/dm_project/rbf.ipynb#ch0000007?line=36'>37</a>\u001b[0m y_pred \u001b[39m=\u001b[39m rbf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/Projects/dm_project/rbf_optimization.py:17\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, X_train, y_train, X_validation, y_validation, normalize, metric)\u001b[0m\n\u001b[1;32m     14\u001b[0m n_clusters \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mn_clusters\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m250\u001b[39m)\n\u001b[1;32m     15\u001b[0m sigma \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m10\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m rbf \u001b[39m=\u001b[39m RBF(n_clusters, sigma, normalize)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     18\u001b[0m y_pred \u001b[39m=\u001b[39m rbf\u001b[39m.\u001b[39mpredict(X_validation)\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m metric(y_validation, y_pred)\n",
      "File \u001b[0;32m~/Projects/dm_project/rbf.py:46\u001b[0m, in \u001b[0;36mRBF.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkmeans\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m     42\u001b[0m \u001b[39m# self.sigmas = [np.cov(X[pred == cluster].T)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m#                for cluster in range(self.n_clusters)]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# phi_j is a scalar representing the activation of the jth cluster wrt its distance with x\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# so for each cluster we need to estimate the best weights\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__phi(X)\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39m=\u001b[39m LinearRegression()\u001b[39m.\u001b[39mfit(phi, y)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Projects/dm_project/rbf.py:29\u001b[0m, in \u001b[0;36mRBF.__phi\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__phi\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m---> 29\u001b[0m         [RBF\u001b[39m.\u001b[39mphi(X, center, sigma)\n\u001b[1;32m     30\u001b[0m          \u001b[39mfor\u001b[39;00m center, sigma \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkmeans\u001b[39m.\u001b[39mcluster_centers_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmas)]\n\u001b[1;32m     31\u001b[0m     )\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/Projects/dm_project/rbf.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__phi\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\n\u001b[0;32m---> 29\u001b[0m         [RBF\u001b[39m.\u001b[39;49mphi(X, center, sigma)\n\u001b[1;32m     30\u001b[0m          \u001b[39mfor\u001b[39;00m center, sigma \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkmeans\u001b[39m.\u001b[39mcluster_centers_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmas)]\n\u001b[1;32m     31\u001b[0m     )\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/Projects/dm_project/rbf.py:23\u001b[0m, in \u001b[0;36mRBF.phi\u001b[0;34m(x, mu, sigma)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mphi\u001b[39m(x, mu, sigma: np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x \u001b[39m-\u001b[39;49m mu, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m sigma\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:2547\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2544\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2545\u001b[0m     \u001b[39m# special case for speedup\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     s \u001b[39m=\u001b[39m (x\u001b[39m.\u001b[39mconj() \u001b[39m*\u001b[39m x)\u001b[39m.\u001b[39mreal\n\u001b[0;32m-> 2547\u001b[0m     \u001b[39mreturn\u001b[39;00m sqrt(add\u001b[39m.\u001b[39;49mreduce(s, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49mkeepdims))\n\u001b[1;32m   2548\u001b[0m \u001b[39m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m \u001b[39m# are valid for vectors\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mord\u001b[39m, \u001b[39mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "cluster_numbers = []\n",
    "standard_deviations = []\n",
    "optimization = np.arange(start=0, stop=N_ESSAIS * len(percentages), step=1)\n",
    "\n",
    "# this took 15 min on my machine with N_ESSAIS = 5\n",
    "for k in range(N_ESSAIS):\n",
    "    seed = random.randint(0, 10000)\n",
    "    random_state = np.random.RandomState(seed)\n",
    "\n",
    "    for p in percentages:\n",
    "\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = get_train_data(\n",
    "            dataset,\n",
    "            targets_columns=['Energy_(kcal/mol)', 'Energy DG:kcal/mol)'],\n",
    "            random_state=random_state,\n",
    "            as_numpy=False,\n",
    "        )\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            study_name=f\"RBF hyperparameters optimization for percentage p={p} Essai={k}\"\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            lambda trial: objective(\n",
    "                trial, X_train, y_train, X_val, y_val, normalize=True, metric=r2_score),\n",
    "            n_trials=10,\n",
    "            # n_jobs=-1\n",
    "        )\n",
    "\n",
    "        rbf = RBF(\n",
    "            study.best_params[\"n_clusters\"],\n",
    "            study.best_params[\"sigma\"],\n",
    "            normalize=True\n",
    "        ).fit(X_train, y_train)\n",
    "        y_pred = rbf.predict(X_test)\n",
    "        mses[k].append(mean_squared_error(y_test, y_pred))\n",
    "        r2_scores[k].append(r2_score(y_test, y_pred))\n",
    "\n",
    "        cluster_numbers.append(study.best_params[\"n_clusters\"])\n",
    "        standard_deviations.append(study.best_params[\"sigma\"])\n",
    "\n",
    "\n",
    "path = Path('./results/rbf')\n",
    "mses = np.array(mses)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "np.save(path/'rbf_mses_var_percentage', mses)\n",
    "np.save(path/'rbf_scores_var_percentage', r2_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f9d0c4f6050>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('./results/rbf')\n",
    "\n",
    "#mses = np.array(mses)\n",
    "#r2_scores = np.array(r2_scores)\n",
    "\n",
    "mses = np.load(path/'rbf_mses_var_percentage.npy')\n",
    "r2_scores = np.load(path/'rbf_scores_var_percentage.npy')\n",
    "\n",
    "np.save(path/'rbf_mses_var_percentage', mses)\n",
    "np.save(path/'rbf_scores_var_percentage', r2_scores)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Mean Squares Error\")\n",
    "plt.xlabel(\"Train Data Percentage\")\n",
    "plt.ylabel(\"Test MSE\")\n",
    "plt.grid(True)\n",
    "\n",
    "final_mses = np.mean(mses, axis=0)\n",
    "mses_error = np.std(mses, axis=0)\n",
    "\n",
    "# remove the fucky percentages\n",
    "rows = np.abs(final_mses) < 10000\n",
    "final_mses_chosen = final_mses[rows][2:]\n",
    "mses_error_chosen = mses_error[rows][2:]\n",
    "percentages_chosen = percentages[rows][2:]\n",
    "\n",
    "plt.semilogy(percentages_chosen, final_mses_chosen, label='Linear Regression')\n",
    "plt.legend()\n",
    "plt.fill_between(percentages_chosen, final_mses_chosen - mses_error_chosen, final_mses_chosen + mses_error_chosen, alpha=0.2, edgecolor='#1B2ACC', facecolor='#089FFF')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"R2 score\")\n",
    "plt.xlabel(\"Train Data Percentage\")\n",
    "plt.ylabel(\"Test R2 score\")\n",
    "plt.grid(True)\n",
    "plt.yscale('linear')\n",
    "\n",
    "final_r2_score = np.mean(r2_scores, axis=0)\n",
    "r2_score_error = np.std(r2_scores, axis=0)\n",
    "\n",
    "# remove fucky values\n",
    "r2_rows = np.abs(final_r2_score) < 10000\n",
    "final_r2_score_chosen = final_r2_score[r2_rows][2:]\n",
    "r2_score_error_chosen = r2_score_error[r2_rows][2:]\n",
    "r2_percentages_chosen = percentages[r2_rows][2:]\n",
    "\n",
    "plt.plot(r2_percentages_chosen, final_r2_score_chosen, label='Linear Regression')\n",
    "plt.legend()\n",
    "plt.fill_between(r2_percentages_chosen, final_r2_score_chosen - r2_score_error_chosen, final_r2_score_chosen + r2_score_error_chosen, alpha=0.2, edgecolor='#1B2ACC', facecolor='#089FFF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-22 03:10:43,590]\u001b[0m A new study created in memory with name: RBF hyperparameters optimization for scale factor s=0.1 Essai=0\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:46,086]\u001b[0m Trial 0 finished with value: 0.18856949906362197 and parameters: {'n_clusters': 135, 'sigma': 0.704540088484537}. Best is trial 0 with value: 0.18856949906362197.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:48,590]\u001b[0m Trial 1 finished with value: 0.8628454647267665 and parameters: {'n_clusters': 118, 'sigma': 3.0437318855280444}. Best is trial 1 with value: 0.8628454647267665.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:50,691]\u001b[0m Trial 2 finished with value: 0.694605301228836 and parameters: {'n_clusters': 86, 'sigma': 1.9316855922489156}. Best is trial 1 with value: 0.8628454647267665.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:53,301]\u001b[0m Trial 3 finished with value: 0.728076651191325 and parameters: {'n_clusters': 179, 'sigma': 1.77802810543794}. Best is trial 1 with value: 0.8628454647267665.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:54,282]\u001b[0m Trial 4 finished with value: 0.9478147408503352 and parameters: {'n_clusters': 53, 'sigma': 8.382489737660826}. Best is trial 4 with value: 0.9478147408503352.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:57,667]\u001b[0m Trial 5 finished with value: 0.8012861507112925 and parameters: {'n_clusters': 244, 'sigma': 1.9503535063669915}. Best is trial 4 with value: 0.9478147408503352.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:10:59,188]\u001b[0m Trial 6 finished with value: 0.9508497907910207 and parameters: {'n_clusters': 88, 'sigma': 6.403909410603762}. Best is trial 6 with value: 0.9508497907910207.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:01,751]\u001b[0m Trial 7 finished with value: 0.8869826125148064 and parameters: {'n_clusters': 175, 'sigma': 3.064000564750328}. Best is trial 6 with value: 0.9508497907910207.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:02,994]\u001b[0m Trial 8 finished with value: 0.9368913470085289 and parameters: {'n_clusters': 75, 'sigma': 5.914812474671732}. Best is trial 6 with value: 0.9508497907910207.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:04,614]\u001b[0m Trial 9 finished with value: 0.8940971687167748 and parameters: {'n_clusters': 102, 'sigma': 4.014633680585162}. Best is trial 6 with value: 0.9508497907910207.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:06,047]\u001b[0m A new study created in memory with name: RBF hyperparameters optimization for scale factor s=0.15918367346938775 Essai=0\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:06,872]\u001b[0m Trial 0 finished with value: 0.5860166874368887 and parameters: {'n_clusters': 39, 'sigma': 1.9729339520408613}. Best is trial 0 with value: 0.5860166874368887.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:09,278]\u001b[0m Trial 1 finished with value: 0.9580382081498632 and parameters: {'n_clusters': 160, 'sigma': 5.420547776867923}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:10,530]\u001b[0m Trial 2 finished with value: 0.9310239783756316 and parameters: {'n_clusters': 78, 'sigma': 6.149883485903676}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:12,533]\u001b[0m Trial 3 finished with value: 0.754829609426467 and parameters: {'n_clusters': 142, 'sigma': 2.187606656598614}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:13,708]\u001b[0m Trial 4 finished with value: 0.9172438105286468 and parameters: {'n_clusters': 69, 'sigma': 5.2947028966755685}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_dense'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n",
      "\u001b[32m[I 2022-06-22 03:11:16,579]\u001b[0m Trial 5 finished with value: 0.9446995734943834 and parameters: {'n_clusters': 143, 'sigma': 4.702925833054136}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:17,055]\u001b[0m Trial 6 finished with value: 0.08492311967137928 and parameters: {'n_clusters': 21, 'sigma': 0.7609722113028929}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:20,883]\u001b[0m Trial 7 finished with value: 0.5195450241473405 and parameters: {'n_clusters': 235, 'sigma': 1.0481213514372938}. Best is trial 1 with value: 0.9580382081498632.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:21,900]\u001b[0m Trial 8 finished with value: 0.96948981441025 and parameters: {'n_clusters': 67, 'sigma': 9.12358619473601}. Best is trial 8 with value: 0.96948981441025.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:22,315]\u001b[0m Trial 9 finished with value: 0.829372997761703 and parameters: {'n_clusters': 18, 'sigma': 9.68478126603798}. Best is trial 8 with value: 0.96948981441025.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:23,607]\u001b[0m A new study created in memory with name: RBF hyperparameters optimization for scale factor s=0.21836734693877552 Essai=0\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:27,094]\u001b[0m Trial 0 finished with value: 0.9346759307093166 and parameters: {'n_clusters': 232, 'sigma': 3.2985239699365327}. Best is trial 0 with value: 0.9346759307093166.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:30,232]\u001b[0m Trial 1 finished with value: 0.9884765353584662 and parameters: {'n_clusters': 180, 'sigma': 8.17591860686301}. Best is trial 1 with value: 0.9884765353584662.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:32,282]\u001b[0m Trial 2 finished with value: 0.9899529374107474 and parameters: {'n_clusters': 119, 'sigma': 9.865892438043433}. Best is trial 2 with value: 0.9899529374107474.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:34,582]\u001b[0m Trial 3 finished with value: 0.9831471651668551 and parameters: {'n_clusters': 136, 'sigma': 7.229209107255426}. Best is trial 2 with value: 0.9899529374107474.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 03:11:34,994]\u001b[0m Trial 4 finished with value: 0.5904787929491672 and parameters: {'n_clusters': 12, 'sigma': 2.7675903742674484}. Best is trial 2 with value: 0.9899529374107474.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "noisy_mses = [[] for _ in range(N_ESSAIS)]\n",
    "noisy_r2_scores = [[] for _ in range(N_ESSAIS)]\n",
    "scale_factors = np.linspace(0.1, 3, 50)\n",
    "\n",
    "for k in range(N_ESSAIS):\n",
    "    for scale_factor in scale_factors:\n",
    "        seed = random.randint(0, 10000)\n",
    "        random_state = np.random.RandomState(seed)\n",
    "        \n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = get_train_data(\n",
    "            dataset,\n",
    "            targets_columns=['Energy_(kcal/mol)', 'Energy DG:kcal/mol)'],\n",
    "            random_state=random_state,\n",
    "            as_numpy=True\n",
    "        )\n",
    "\n",
    "        # add noise to the first three columns which are our continuous features.\n",
    "        X_train[:, 0] += np.random.normal(scale=scale_factor*np.std(X_train[:, 0]), size=X_train.shape[0])\n",
    "        X_train[:, 1] += np.random.normal(scale=scale_factor*np.std(X_train[:, 1]), size=X_train.shape[0])\n",
    "        X_train[:, 2] += np.random.normal(scale=scale_factor*np.std(X_train[:, 2]), size=X_train.shape[0])\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            study_name=f\"RBF hyperparameters optimization for scale factor s={scale_factor} Essai={k}\"\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            lambda trial: objective(\n",
    "                trial, X_train, y_train, X_val, y_val, normalize=True, metric=r2_score),\n",
    "            n_trials=10,\n",
    "            # n_jobs=-1\n",
    "        )\n",
    "                \n",
    "        rbf = RBF(\n",
    "            study.best_params[\"n_clusters\"], \n",
    "            study.best_params[\"sigma\"],\n",
    "            normalize=True\n",
    "        ).fit(X_train, y_train)\n",
    "        y_pred = rbf.predict(X_test)\n",
    "        noisy_mses[k].append(mean_squared_error(y_test, y_pred))\n",
    "        noisy_r2_scores[k].append(r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
