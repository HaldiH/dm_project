{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras and Tensorflow Neural Network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset shape = (39926, 24)  Pruned dataset shape = (12865, 6)\n",
      "Encoded dataset shape = (12865, 35)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from processing_utils import *\n",
    "\n",
    "raw_dataset = pd.read_csv('./dataset/data.csv')\n",
    "\n",
    "pruned_dataset = prune_dataset_lines(raw_dataset, remove_nan_lines=False, remove_nan_cols=True)\n",
    "print(\"Raw dataset shape =\", raw_dataset.shape, \" Pruned dataset shape =\", pruned_dataset.shape)\n",
    "\n",
    "encoded_pruned_data = encode_smiles_column_of(pruned_dataset, 'count_encoding') # change to one_hot_encoding here\n",
    "print(\"Encoded dataset shape =\", encoded_pruned_data.shape)\n",
    "\n",
    "X_train, y_train, X_test, y_test = return_required_data(\n",
    "    encoded_pruned_data, \n",
    "    ['Energy_(kcal/mol)', 'Energy DG:kcal/mol)'], \n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9005, 33) (9005, 2) (3860, 33) (3860, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "tiny_model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='elu', input_dim=33),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "tiny_model.compile(loss='mse', optimizer='sgd', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5737 - mse: 0.5737 - val_loss: 0.3610 - val_mse: 0.3610\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2788 - mse: 0.2788 - val_loss: 0.2132 - val_mse: 0.2132\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1806 - mse: 0.1806 - val_loss: 0.1538 - val_mse: 0.1538\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1243 - val_mse: 0.1243\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.1121 - mse: 0.1121 - val_loss: 0.1043 - val_mse: 0.1043\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0906 - val_mse: 0.0906\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0824 - mse: 0.0824 - val_loss: 0.0794 - val_mse: 0.0794\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0726 - mse: 0.0726 - val_loss: 0.0730 - val_mse: 0.0730\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0669 - mse: 0.0669 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0582 - val_mse: 0.0582\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0531 - val_mse: 0.0531\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0428 - val_mse: 0.0428\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0466 - val_mse: 0.0466\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0286 - val_mse: 0.0286\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0284 - val_mse: 0.0284\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0117 - val_mse: 0.0117\n"
     ]
    }
   ],
   "source": [
    "histories = {}\n",
    "histories['Tiny'] = tiny_model.fit(X_train, y_train, epochs=150, batch_size=500, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric='mse')\n",
    "plotter.plot(histories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9005, 33) (9005, 2) (3860, 33) (3860, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fat_model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_dim=33),\n",
    "    keras.layers.Dense(512, activation='relu', input_dim=512),\n",
    "    keras.layers.Dense(512, activation='relu', input_dim=512),\n",
    "    keras.layers.Dense(512, activation='relu', input_dim=512),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "fat_model.compile(loss='mse', optimizer='sgd', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 1s 22ms/step - loss: 0.9277 - mse: 0.9277 - val_loss: 0.8052 - val_mse: 0.8052\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.7078 - mse: 0.7078 - val_loss: 0.5841 - val_mse: 0.5841\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.4843 - mse: 0.4843 - val_loss: 0.3778 - val_mse: 0.3778\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.3002 - mse: 0.3002 - val_loss: 0.2316 - val_mse: 0.2316\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1822 - mse: 0.1822 - val_loss: 0.1478 - val_mse: 0.1478\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.1345 - val_mse: 0.1345\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0766 - mse: 0.0766 - val_loss: 0.0793 - val_mse: 0.0793\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0557 - mse: 0.0557 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 59/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 64/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 66/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 70/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 73/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 76/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 79/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 88/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 89/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 97/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - 1s 39ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - 0s 21ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 111/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 112/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 113/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - 0s 23ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 116/1000\n",
      " 1/19 [>.............................] - ETA: 0s - loss: 0.0051 - mse: 0.0051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gordon/Documents/gordon_bsci/Sem6/Data Mining/TPs/Project/keras.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000006?line=0'>1</a>\u001b[0m histories[\u001b[39m'\u001b[39m\u001b[39mFat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fat_model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories['Fat'] = fat_model.fit(X_train, y_train, epochs=150, batch_size=500, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfdocs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gordon/Documents/gordon_bsci/Sem6/Data Mining/TPs/Project/keras.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000001?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39myscale(\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000001?line=3'>4</a>\u001b[0m plotter \u001b[39m=\u001b[39m tfdocs\u001b[39m.\u001b[39mplots\u001b[39m.\u001b[39mHistoryPlotter(metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000001?line=4'>5</a>\u001b[0m plotter\u001b[39m.\u001b[39mplot(histories)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gordon/Documents/gordon_bsci/Sem6/Data%20Mining/TPs/Project/keras.ipynb#ch0000001?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(mean_squared_error(y_test[:\u001b[39m10\u001b[39m, :], fat_model\u001b[39m.\u001b[39mpredict(X_test[:\u001b[39m10\u001b[39m, :])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfdocs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric='mse')\n",
    "plotter.plot(histories)\n",
    "\n",
    "print(mean_squared_error(y_test[:10, :], fat_model.predict(X_test[:10, :])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
